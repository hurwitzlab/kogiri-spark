#!/usr/bin/env python

import os
#from pyspark import SparkContext
from Bio import SeqIO
#import argparse
import sys
import pprint

# --------------------------------------------------
def usage(msg=""):
  if len(msg):
    print(msg)

  print('%s input output' % sys.argv[0])
  sys.exit(2)

# --------------------------------------------------
def main(argv):                         
#  parser = argparse.ArgumentParser()
#  parser.add_argument('-i', '--in')
#  parser.add_argument('-o', '--out')
#  args = parser.parse_args()
#
#  pprint.pprint(args)
  
  if len(argv) != 2:
    usage()

  in_dir  = argv[0] # '/home/kyclark/data/pov'
  out_dir = argv[1] # '/user/metagenomics/pov/fasta-seq'

  if not os.path.isdir(in_dir): 
    usage("Bad directory (%s)" % in_dir)

  files = os.listdir(in_dir)

  if len(files) == 0:
    usage("Dir '%s' is empty" % in_dir)

#  sc = SparkContext(appName="fasta-parser")

  fNum = 0
  for file in files:
    fNum += 1
    print("%5d: %s" % (fNum, file))

    handle = open(os.path.join(in_dir, file), "rU")
    seqs   = []
    i      = 0

    for record in SeqIO.parse(handle, "fasta") :
      i += 1
      seqs.append((i, str(record.seq)))

    handle.close()

    rdd = sc.parallelize(seqs)
    dir = os.path.join(out_dir, os.path.basename(file))

    rdd.saveAsSequenceFile(dir)

# --------------------------------------------------
if __name__ == "__main__":
  main(sys.argv[1:])
